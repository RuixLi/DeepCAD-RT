import os
import torch
import torch.nn as nn
from torch.autograd import Variable
from torch.utils.data import DataLoader
import argparse
import time
import datetime
from network import Network_3D_Unet
import numpy as np
from utils import save_yaml, read_yaml
from data_process import test_preprocess_lessMemoryNoTail_chooseOne, testset, multibatch_test_save, singlebatch_test_save
from skimage import io

#############################################################################################################################################
parser = argparse.ArgumentParser()
parser.add_argument("--n_epochs", type=int, default=100, help="number of training epochs")
parser.add_argument('--GPU', type=str, default='0', help="the index of GPU you will use for computation")

parser.add_argument('--batch_size', type=int, default=1, help="batch size")
parser.add_argument('--img_w', type=int, default=128, help="the width of image sequence")
parser.add_argument('--img_h', type=int, default=128, help="the height of image sequence")
parser.add_argument('--img_s', type=int, default=100, help="the slices of image sequence")
parser.add_argument('--gap_w', type=int, default=64, help='the width of image gap')
parser.add_argument('--gap_h', type=int, default=64, help='the height of image gap')
parser.add_argument('--gap_s', type=int, default=50, help='the slices of image gap')

parser.add_argument('--lr', type=float, default=0.00005, help='initial learning rate')
parser.add_argument("--b1", type=float, default=0.5, help="Adam: bata1")
parser.add_argument("--b2", type=float, default=0.999, help="Adam: bata2")
parser.add_argument('--normalize_factor', type=int, default=1, help='normalize factor')
parser.add_argument('--fmap', type=int, default=16, help='number of feature maps')

parser.add_argument('--output_dir', type=str, default='./results', help="output directory")
parser.add_argument('--datasets_path', type=str, default='datasets', help="dataset root path")
parser.add_argument('--pth_path', type=str, default='pth', help="pth file root path")
parser.add_argument('--datasets_folder', type=str, default='noiseData', help="A folder containing files to be tested")
parser.add_argument('--denoise_model', type=str, default='GCaMPtg', help='A folder containing models to be tested')
parser.add_argument('--test_datasize', type=int, default=3500, help='dataset size to be tested')
parser.add_argument('--train_datasets_size', type=int, default=100000, help='datasets size for training')

opt = parser.parse_args()
opt.ngpu=str(opt.GPU).count(',')+1
print('\033[1;31m -- Using Parameters -- \033[0m')
print(opt)
batch_size = opt.batch_size

def test(opt):
########################################################################################################################
    print('\033[1;31m -- Loading Models -- \033[0m')
    os.environ["CUDA_VISIBLE_DEVICES"] = str(opt.GPU)
    model_path = opt.pth_path + '//' + opt.denoise_model
    #print('Get models from:', model_path)
    model_list = list(os.walk(model_path, topdown=False))[-1][-1]
    model_list.sort()
    #print(model_list)

    # read paremeters from file
    for i in range(len(model_list)):
        aaa = model_list[i]
        if '.yaml' in aaa:
            yaml_name = model_list[i]
            del model_list[i]
    #print(yaml_name)
    print('Get %d models' %len(model_list))
    read_yaml(opt, model_path + '//' + yaml_name)

    # get stacks for processing
    im_folder = opt.datasets_path + '//' + opt.datasets_folder
    f_list = list(os.walk(im_folder, topdown=False))[-1][-1]
    img_list = [f for f in f_list if (f.endswith('.tif') or f.endswith('.tiff'))]
    img_list.sort()

    print('\033[1;31m -- Data List to Process -- \033[0m')
    print(' >>>> Total number: %d <<<<' %len(img_list))
    for img in img_list: print(img)

    if not os.path.exists(opt.output_dir):
        os.mkdir(opt.output_dir)
    current_time = datetime.datetime.now().strftime("%Y%m%d%H%M")
    output_path1 = opt.output_dir + '//' + 'DataFolderIs_' + opt.datasets_folder + '_' + current_time + '_ModelFolderIs_' + opt.denoise_model
    if not os.path.exists(output_path1):
        os.mkdir(output_path1)

    yaml_name = output_path1 + '//para.yaml'
    save_yaml(opt, yaml_name)

    ##############################################################################################################################################################
    # network architecture and GPU access
    denoise_generator = Network_3D_Unet(in_channels=1,
                                        out_channels=1,
                                        f_maps=opt.fmap,
                                        final_sigmoid=True)
    if torch.cuda.is_available():
        print('\033[1;31m -- Using {} GPU -- \033[0m'.format(torch.cuda.device_count()))
        denoise_generator = denoise_generator.cuda()
        denoise_generator = nn.DataParallel(denoise_generator, device_ids=range(opt.ngpu))
        tdevice = 'gpu'
    else:
        print('\033[1;31m -- Using CPU -- \033[0m')
        tdevice = 'cpu'

    cuda = True if torch.cuda.is_available() else False
    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor
    ##############################################################################################################################################################
    print('\033[1;31m -- Start Processing -- \033[0m')

    for pth_index in range(len(model_list)):
        aaa = model_list[pth_index]
        if '.pth' in aaa:
            pth_name = model_list[pth_index]
            output_path = output_path1 + '//' + pth_name.replace('.pth', '_generatedData')
            if not os.path.exists(output_path):
                os.mkdir(output_path)
        print('Loaded Model[%d/%d]: %s' % (pth_index+1,len(model_list),pth_name))
        # load model
        model_name = opt.pth_path + '//' + opt.denoise_model + '//' + pth_name
        if isinstance(denoise_generator, nn.DataParallel):
            denoise_generator.module.load_state_dict(torch.load(model_name))  # parallel
            denoise_generator.eval()
            num_workers = 4
        else:
            denoise_generator.load_state_dict(torch.load(model_name,map_location=torch.device(tdevice)))  # not parallel
            denoise_generator.eval()
            num_workers = 0
        if cuda:
            denoise_generator.cuda()

            # test all stacks
        for N in range(len(img_list)):
            name_list, noise_img, coordinate_list = test_preprocess_lessMemoryNoTail_chooseOne(opt, N)
            #print(len(name_list))
            prev_time = time.time()
            time_start = time.time()
            denoise_img = np.zeros(noise_img.shape)
            input_img = np.zeros(noise_img.shape)

            test_data = testset(name_list, coordinate_list, noise_img)
            testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)

            for iteration, (noise_patch,single_coordinate) in enumerate(testloader):
                if cuda:
                    real_A = noise_patch.cuda()
                else:
                    real_A = noise_patch
                #print('real_A -----> ',real_A.shape)
                #input_name = name_list[index]
                # print(' input_name -----> ',input_name)
                #print(' single_coordinate -----> ',single_coordinate)
                # print('real_A -----> ',real_A.shape)
                real_A = Variable(real_A)
                fake_B = denoise_generator(real_A)
                ################################################################################################################
                # Determine approximate time left
                batches_done = iteration
                batches_left = 1 * len(testloader) - batches_done
                time_left_seconds = int(batches_left * (time.time() - prev_time))
                time_left = datetime.timedelta(seconds=time_left_seconds)
                prev_time = time.time()
                ################################################################################################################
                if iteration % 1 == 0:
                    time_end = time.time()
                    time_cost = time_end - time_start  # datetime.timedelta(seconds= (time_end - time_start))
                    print(
                        '\rData[%d/%d]:%s | Patch %d/%d | Time Cost: %.0d s (ETA: %s s)     '
                        % (
                            N + 1,
                            len(img_list),
                            img_list[N],
                            iteration + 1,
                            len(testloader),
                            time_cost,
                            time_left_seconds
                        ), end=' ')

                if (iteration + 1) % len(testloader) == 0:
                    print('\n', end=' ')
                ################################################################################################################
                output_image = np.squeeze(fake_B.cpu().detach().numpy())
                raw_image = np.squeeze(real_A.cpu().detach().numpy())
                if(output_image.ndim==3):
                    turn=1
                else:
                    turn=output_image.shape[0]
                #print(turn)
                if(turn>1):
                    for id in range(turn):
                        #print('shape of output_image -----> ',output_image.shape)
                        aaaa,bbbb,stack_start_w,stack_end_w,stack_start_h,stack_end_h,stack_start_s,stack_end_s = multibatch_test_save(single_coordinate,id,output_image,raw_image)
                        denoise_img[stack_start_s:stack_end_s, stack_start_h:stack_end_h, stack_start_w:stack_end_w] = aaaa * (np.sum(bbbb) / np.sum(aaaa)) ** 0.5
                        input_img[stack_start_s:stack_end_s, stack_start_h:stack_end_h, stack_start_w:stack_end_w] = bbbb
                else:
                    aaaa, bbbb, stack_start_w, stack_end_w, stack_start_h, stack_end_h, stack_start_s, stack_end_s = singlebatch_test_save(single_coordinate, output_image, raw_image)
                    denoise_img[stack_start_s:stack_end_s, stack_start_h:stack_end_h, stack_start_w:stack_end_w] = aaaa * (np.sum(bbbb) / np.sum(aaaa)) ** 0.5
                    input_img[stack_start_s:stack_end_s, stack_start_h:stack_end_h, stack_start_w:stack_end_w] = bbbb

            print('\033[1;31m -- Save Results -- \033[0m')
            # del noise_img
            output_img = denoise_img.squeeze().astype(np.float32) * opt.normalize_factor
            del denoise_img
            # output_img = output_img1[0:raw_noise_img.shape[0],0:raw_noise_img.shape[1],0:raw_noise_img.shape[2]]
            output_img = output_img - output_img.min()
            output_img = output_img / output_img.max() * 65535
            output_img = np.clip(output_img, 0, 65535).astype('uint16')
            output_img = output_img - output_img.min()
            # output_img = output_img.astype('uint16')

            result_name = output_path + '//' + img_list[N].replace('.tif', '') + '_' + pth_name.replace('.pth', '') + '_output.tif'
            io.imsave(result_name, output_img, check_contrast=False)


###########################################
if __name__ == '__main__':
    test(opt)